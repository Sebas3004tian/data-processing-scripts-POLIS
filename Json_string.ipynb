{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importaciones necesarias para que funcione el codigo\n",
    "import pandas as pd\n",
    "import pyreadr\n",
    "import os\n",
    "import numpy as np\n",
    "import ast\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui abajo vamos a crear la carpeta \"insumos\" que es donde guardaremos los insumos necesarios, tambien en este caso se almacenan las salidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de la carpeta donde antes de ejecutar el script se guardan los datos\n",
    "carpeta = \"insumos\"\n",
    "if not os.path.exists(carpeta):\n",
    "    os.makedirs(carpeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este codigo de abajo lee la base de datos y le da el nombre de df(tipo de Dato DataFrame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"insumos/reportTQ.csv\", delimiter=\";\")\n",
    "#Leer el archivo de esa ruta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este codigo vemos la dimension de la df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El .head nos ayuda a ver un resumen de la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos codigos son metodos que serviran mas adelante para buscar todas las columnas en formato lista y todas las columnas en formato json.\n",
    "\n",
    "\n",
    "!! Recuerda que solo se ejecuta una funcion una vez se llame, aqui solo las estamos definiendo (No hacen nada aun)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_list_columns(df):\n",
    "    list_columns = []\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            if df[col].apply(lambda x: isinstance(x, list) or isinstance(ast.literal_eval(x), list) if isinstance(x, str) else False).any():\n",
    "                list_columns.append(col)\n",
    "        except (ValueError, SyntaxError):\n",
    "            continue  # Ignora errores de conversión\n",
    "    return list_columns\n",
    "\n",
    "def find_json_columns(df):\n",
    "    json_columns = []\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            if df[col].apply(lambda x: isinstance(x, dict) or isinstance(json.loads(x), dict) if isinstance(x, str) else False).any():\n",
    "                json_columns.append(col)\n",
    "        except (json.JSONDecodeError, TypeError):\n",
    "            continue\n",
    "    return json_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expande una columna que contiene listas en múltiples columnas, \n",
    "    mostrando el valor si está presente y NaN si no.\n",
    "\n",
    "Y el otro Expande columnas específicas que contienen JSON en múltiples columnas con claves como nombres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_list_column_text(df, column_name):\n",
    "    \"\"\"\n",
    "    Expande una columna que contiene listas en múltiples columnas, \n",
    "    mostrando el valor si está presente y NaN si no.\n",
    "\n",
    "    Parámetros:\n",
    "    - df: DataFrame de pandas.\n",
    "    - column_name: Nombre de la columna a expandir.\n",
    "\n",
    "    Retorna:\n",
    "    - DataFrame modificado con nuevas columnas de texto.\n",
    "    \"\"\"\n",
    "    unique_values = set()\n",
    "\n",
    "    # Paso 1: Extraer todos los valores únicos sin repetir\n",
    "    for row in df[column_name].dropna():\n",
    "        try:\n",
    "            parsed_list = json.loads(row) if isinstance(row, str) else row\n",
    "            if isinstance(parsed_list, list):\n",
    "                unique_values.update(parsed_list)  # Agregar valores únicos\n",
    "        except json.JSONDecodeError:\n",
    "            continue  # Ignorar errores en JSON mal formateado\n",
    "\n",
    "    # Paso 2: Crear nuevas columnas con el valor en texto si está presente\n",
    "    i=1\n",
    "    for value in sorted(unique_values):  # Ordenamos para mantener consistencia\n",
    "        col_name = f\"{column_name}_opcion{i}_{value}\"\n",
    "        df[col_name] = df[column_name].apply(\n",
    "            lambda x: value if isinstance(x, str) and value in json.loads(x) else None\n",
    "        )\n",
    "        i+=1\n",
    "    return df\n",
    "\n",
    "def expand_json_columns(df, json_col):\n",
    "    \"\"\"\n",
    "    Expande columnas específicas que contienen JSON en múltiples columnas con claves como nombres.\n",
    "    \n",
    "    Parámetros:\n",
    "    - df: DataFrame de pandas con algunas columnas que contienen JSON.\n",
    "    - json_cols: Lista de nombres de columnas a expandir.\n",
    "    \n",
    "    Retorna:\n",
    "    - DataFrame con las columnas JSON expandidas.\n",
    "    \"\"\"\n",
    "    new_columns = {}\n",
    "    column=json_col\n",
    "    if column in df.columns:\n",
    "        sample_data = df[column].dropna().astype(str).values\n",
    "        \n",
    "        for entry in sample_data:\n",
    "            try:\n",
    "                parsed_json = json.loads(entry)\n",
    "                if isinstance(parsed_json, dict):\n",
    "                    for key in parsed_json.keys():\n",
    "                        new_col_name = f\"{column}_{key}\"\n",
    "                        if new_col_name not in new_columns:\n",
    "                            new_columns[new_col_name] = []\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    \n",
    "    # Crear nuevas columnas en el DataFrame\n",
    "    i=1\n",
    "    for new_col in new_columns.keys():\n",
    "        original_col, key = new_col.rsplit('_', 1)\n",
    "        new_col_name = f\"{original_col}_opcion{i}_{key}\"  # Agregar \"opcion\" en el nombre\n",
    "        df[new_col_name] = df[original_col].apply(lambda x: json.loads(x).get(key) if isinstance(x, str) else None)\n",
    "        i+=1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecuta esto si quieres modificar manualmente la lista de JSON Colums y la lista de List Colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_cols = [\n",
    "    \"826 - La empresa\",\n",
    "    \"827 - Fondo de empleados de la empresa\",\n",
    "    \"828 - Entidad financiera y/o tarjetas de crédito\",\n",
    "    \"829 - Prestamista/Gota a gota\",\n",
    "    \"830 - Icetex\",\n",
    "    \"831 - Familiar o amigo\",\n",
    "    \"832 - Comfandi/Caja de Compensación Familiar\",\n",
    "    \"833 - Otro\",\n",
    "    \"834 - Seleccione el nivel de formación de su mayor interés:\",\n",
    "    \"851 - ¿Cuántos días realizó actividades físicas intensas? (ej. Levantar pesos pesados, correr, andar rápido o en bicicleta)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cols = [\n",
    "    \"899 - ¿Cuál considera que debe ser el rol de los padres en la educación de los hijos? (Seleccione las tres opciones que mejor describan su opinión)\",\n",
    "    \"911 - ¿Cómo puede influir una buena educación en las oportunidades futuras de los hijos? (Seleccione las tres opciones que mejor describan su opinión)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecuta esto si quieres que la busqueda sea automatica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cols = find_list_columns(df)\n",
    "\n",
    "print(\"Columnas con listas:\", list_cols)\n",
    "print(\"Numero de listas:\", len(list_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_cols = find_json_columns(df)\n",
    "\n",
    "print(\"Columnas con JSON:\", json_cols)\n",
    "print(\"Numero de JSON:\", len(json_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numJsonCols=len(json_cols)\n",
    "numListCols=len(list_cols)\n",
    "\n",
    "print(\"numero de columnas Json:\", numJsonCols)\n",
    "print(\"numero de columnas en List:\", numListCols)\n",
    "\n",
    "print(\"Numero de columnas:\", df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flujo normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es necesario tener el \"nameEspecialColumn\" y el \"ignore_cols\" asi sea lo mismo, ya que ignore_cols se refiere a las columnas por ignorar, pueden ser una o varias, la especial si es solo una y solo funciona para esa forma en la que esta esa columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nombre de la columna especial\n",
    "nameEspecialColumn=\"785 - Describa los miembros de su familia con los que convive actualmente (Incluyéndose usted):\"\n",
    "\n",
    "# Especificar columnas a ignorar\n",
    "ignore_cols = [\"785 - Describa los miembros de su familia con los que convive actualmente (Incluyéndose usted):\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expandir columnas de listas\n",
    "for list_col in list_cols:\n",
    "    if list_col in ignore_cols:\n",
    "            continue  # Ignorar columnas especificadas\n",
    "    else:\n",
    "        df = expand_list_column_text(df, list_col)\n",
    "\n",
    "\n",
    "# Expandir columnas de JSON\n",
    "for json_col in json_cols:\n",
    "    if json_col in ignore_cols:\n",
    "            continue  # Ignorar columnas especificadas\n",
    "    else:\n",
    "        df = expand_json_columns(df, json_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar list_cols para excluir las columnas en ignore_cols\n",
    "cols_to_drop = [col for col in list_cols if col not in ignore_cols]\n",
    "# Eliminar las columnas del DataFrame\n",
    "df = df.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "# Filtrar list_cols para excluir las columnas en ignore_cols\n",
    "cols_to_drop = [col for col in json_cols if col not in ignore_cols]\n",
    "# Eliminar las columnas del DataFrame\n",
    "df = df.drop(columns=cols_to_drop, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Asegurar que no haya valores NaN en la columna antes de convertir\n",
    "df[nameEspecialColumn] = df[nameEspecialColumn].fillna(\"[]\")  # Reemplaza NaN con una lista vacía\n",
    "# Convertir la columna de strings en listas de diccionarios (JSONs)\n",
    "df[nameEspecialColumn] = df[nameEspecialColumn].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)  \n",
    "\n",
    "# Encontrar la cantidad máxima de JSONs en cualquier fila\n",
    "max_jsons = df[nameEspecialColumn].apply(len).max()\n",
    "\n",
    "# Expandir los JSONs en columnas separadas\n",
    "df_expanded = df[nameEspecialColumn].apply(lambda x: x + [{}] * (max_jsons - len(x)))  # Asegurar que todas las listas tengan la misma longitud\n",
    "df_expanded = pd.DataFrame(df_expanded.tolist()).add_prefix(f\"{nameEspecialColumn}_opcion\")  # Convertir a DataFrame y agregar prefijo\n",
    "df_expanded.columns = [f\"{nameEspecialColumn}_opcion{i+1}\" for i in range(df_expanded.shape[1])]\n",
    "\n",
    "\n",
    "# Unir con el DataFrame original sin la columna inicial\n",
    "df = pd.concat([df.drop(columns=[nameEspecialColumn]), df_expanded], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expandir cada columna de JSON en sus propias columnas\n",
    "df = pd.concat(\n",
    "    [df.drop(columns=df.filter(like=f\"{nameEspecialColumn}_opcion\").columns)] + \n",
    "    [df[f\"{nameEspecialColumn}_opcion{i+1}\"].apply(pd.Series).add_prefix(f\"{nameEspecialColumn}_opcion{i+1}_\") for i in range(max_jsons)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este bloque de codigo, Ordena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de columnas iniciales que no deben cambiar su posición\n",
    "fixed_columns = [\"ID\", \"Survey\", \"TimeStart\", \"TimeEnd\", \"TimeDiff\", \n",
    "                 \"IsFinished\", \"Interviewer\", \"Username\", \"Nit\", \"Institution\"]\n",
    "\n",
    "# Extraer las demás columnas y ordenarlas\n",
    "other_columns = sorted([col for col in df.columns if col not in fixed_columns])\n",
    "\n",
    "# Reorganizar el DataFrame\n",
    "df = df[fixed_columns + other_columns]\n",
    "\n",
    "# Mostrar el DataFrame reorganizado\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar a Excel\n",
    "df.to_excel(\"insumos/reportTQ_limpiado.xlsx\", index=False)\n",
    "\n",
    "# Exportar a CSV con separador ';'\n",
    "df.to_csv(\"insumos/reportTQ_limpiado.csv\", index=False, sep=';', encoding='utf-8')\n",
    "\n",
    "print(\"Archivos Excel y CSV generados correctamente.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
