{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODIGOS PRINCIPALES CALIPEDIA-CALIBRANDO\n",
    "\n",
    "Siempre que lo abras, ejecuta las importaciones!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este codigo ------->   pip install pandas pyreadr numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importaciones necesarias para que funcione el codigo\n",
    "import pandas as pd\n",
    "import pyreadr\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionalmente, para ejecutar correctamente este codigo, necesitamos tener los insumos (Base de datos en este caso \"CaliBRANDO2024.dta\") necesarios, para facilitar la comprension, estos insumos se cargaran en la carpeta \"insumos\" (Tranquilo si no la tienes el siguiente codigo la ejecutará).\n",
    "\n",
    "Tambien, es necesario saber que se debe ejecutar en orden, ya que como en R, aqui usaremos variables, listas, dataFrames, etc... , que se usaran mas adelante. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de la carpeta donde antes de ejecutar el script se guardan los datos CaliBRANDO2024.dta\n",
    "carpeta = \"insumos\"\n",
    "if not os.path.exists(carpeta):\n",
    "    os.makedirs(carpeta)\n",
    "\n",
    "carpeta = \"insumos/data\"\n",
    "if not os.path.exists(carpeta):\n",
    "    os.makedirs(carpeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta linea es unicamente para cargar la base de datos, le llamamos df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata(\"insumos/data/Panel 2023_ 1.dta\")  # Leer el archivo .dta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las primeras filas del DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = df.shape  # Obtener la forma del DataFrame  \n",
    "print(shape)  # Mostrar la forma del DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MENTAL HEALTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTA: \n",
    "Los siguientes codigos indican el procesamiento de las variables de interes para calcular indicadores de estres, depresion y ansiedad\n",
    "\n",
    "* Estres: P10000801 P10000802 P10000803 P10000804 P10000805 P10000806 P10000807 P10000808 P10000809 P100008010\n",
    "* Ansiedad: P10000901 P10000902 P10000903 P10000904 P10000905 P10000906 P10000907\n",
    "* Depresion: P10001001 P10001002 P10001003 P10001004 P10001005 P10001006 P10001007 P10001008 P10001009"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recode Estres: Estres autopercibido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_categoricas=[\"P10000801\", \"P10000802\", \"P10000803\", \"P10000804\", \"P10000805\", \"P10000806\", \"P10000807\", \"P10000808\", \"P10000809\", \"P10000810\"]\n",
    "cols_invertir = [\"P10000804\", \"P10000805\", \"P10000807\", \"P10000808\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[cols_categoricas].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols_categoricas:\n",
    "    print(f\"{col}: {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeo de categorías a valores numéricos\n",
    "mapa_categorias = {\n",
    "    \"Nunca\": 0,\n",
    "    \"Casi Nunca\": 1,\n",
    "    \"De vez en cuando\": 2,\n",
    "    \"A menudo\": 3,\n",
    "    \"Muy amenudo\": 4,\n",
    "    \"No\": 0,\n",
    "    \"Si\": 1\n",
    "}\n",
    "\n",
    "# Convertir categorías a valores numéricos\n",
    "for col in cols_categoricas:\n",
    "    df[col] = df[col].map(mapa_categorias).astype(\"float64\")\n",
    "\n",
    "# Función corregida para invertir la escala (de 0 a 4)\n",
    "def invertir_escala(valor):\n",
    "    if pd.notna(valor):  # Verifica que el valor no sea NaN\n",
    "        return 4 - valor  # Invierte la escala correctamente\n",
    "    return valor  # Si es NaN, lo deja igual\n",
    "\n",
    "# Aplicar la función a las columnas invertidas\n",
    "for col in cols_invertir:\n",
    "    df[f\"in_{col}\"] = df[col].apply(invertir_escala)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"estresado\"] = (\n",
    "    df[[\"P10000801\", \"P10000802\", \"P10000803\", \"in_P10000804\",\n",
    "        \"in_P10000805\", \"P10000806\", \"in_P10000807\", \"in_P10000808\",\n",
    "        \"P10000809\", \"P10000810\"]]\n",
    "    .fillna(0)  # Reemplaza NaN con 0\n",
    "    .sum(axis=1)  # Suma fila por fila\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular frecuencia y porcentaje\n",
    "frecuencia = df[\"in_P10000808\"].value_counts(dropna=False)  \n",
    "porcentaje = df[\"in_P10000808\"].value_counts(normalize=True, dropna=False) * 100  \n",
    "\n",
    "# Crear DataFrame\n",
    "tabla_frecuencia = pd.DataFrame({\n",
    "    \"Frecuencia\": frecuencia,\n",
    "    \"Porcentaje\": porcentaje\n",
    "})\n",
    "\n",
    "# Agregar columna de frecuencia acumulada\n",
    "tabla_frecuencia[\"Frecuencia Acumulada\"] = tabla_frecuencia[\"Frecuencia\"].cumsum()\n",
    "tabla_frecuencia[\"Porcentaje Acumulado\"] = tabla_frecuencia[\"Porcentaje\"].cumsum()\n",
    "\n",
    "# Agregar fila de totales\n",
    "total_frecuencia = tabla_frecuencia[\"Frecuencia\"].sum()\n",
    "total_porcentaje = tabla_frecuencia[\"Porcentaje\"].sum()\n",
    "tabla_frecuencia.loc[\"Total\"] = [total_frecuencia, total_porcentaje, None, None]\n",
    "\n",
    "print(tabla_frecuencia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular frecuencia absoluta\n",
    "frecuencia = df[\"in_P10000808\"].value_counts(dropna=False).sort_index()\n",
    "\n",
    "# Calcular total sin incluir NaN\n",
    "total_sin_na = df[\"in_P10000808\"].count()\n",
    "\n",
    "# Calcular porcentajes correctamente\n",
    "porcentaje = (frecuencia / total_sin_na) * 100\n",
    "\n",
    "# Crear DataFrame\n",
    "tabla_frecuencia = pd.DataFrame({\n",
    "    \"Freq.\": frecuencia,\n",
    "    \"Percent\": porcentaje\n",
    "})\n",
    "\n",
    "# Agregar columna acumulada\n",
    "tabla_frecuencia[\"Cum.\"] = tabla_frecuencia[\"Percent\"].cumsum()\n",
    "\n",
    "# Agregar fila de totales\n",
    "tabla_frecuencia.loc[\"Total\"] = [frecuencia.sum(), 100, None]\n",
    "\n",
    "# Redondear como en Stata\n",
    "tabla_frecuencia = tabla_frecuencia.round(2)\n",
    "\n",
    "print(tabla_frecuencia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"in_P10000808\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"estresado\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasificar en categoría de estrés (1 = estresado, 0 = no estresado)\n",
    "df[\"cat_estres\"] = df[\"estresado\"].apply(lambda x: 1 if x >= 15 else 0)\n",
    "\n",
    "# Contar cuántas personas hay en cada categoría\n",
    "print(df[\"cat_estres\"].value_counts())\n",
    "\n",
    "# Mostrar en porcentaje\n",
    "print(df[\"cat_estres\"].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance afectivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se refiere a la diferencia entre la felicidad percibida del\n",
    "individuo y su preocupacion. Esta variable fue normalizada entre 0 y 1 para compararse\n",
    "con la medida de satisfacción con la vida y mantener una mejor interpretacion del balance\n",
    "afectivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"P03001501\"].cat.categories)\n",
    "print(df[\"P03000601\"].cat.categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeo de valores categóricos a números\n",
    "mapeo = {\n",
    "    \"En ningún momento\": 0,\n",
    "    \"Todo el tiempo\": 10\n",
    "}\n",
    "\n",
    "# Reemplazar y convertir a float\n",
    "df[\"P03001501\"] = df[\"P03001501\"].replace(mapeo).astype(float)\n",
    "df[\"P03000601\"] = df[\"P03000601\"].replace(mapeo).astype(float)\n",
    "\n",
    "# Verificar que la conversión fue exitosa\n",
    "print(df[[\"P03001501\", \"P03000601\"]].dtypes)  # Ambas deben ser float\n",
    "print(df[[\"P03001501\", \"P03000601\"]].head())  # Verificar valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"balance_afectivo\"] = df[\"P03001501\"] - df[\"P03000601\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"balance_afectivo\"] = (df[\"balance_afectivo\"] - df[\"balance_afectivo\"].min()) / (df[\"balance_afectivo\"].max() - df[\"balance_afectivo\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"balance_afectivo\"].describe())  # Para ver estadísticas\n",
    "print(df[\"balance_afectivo\"].head())  # Para ver los primeros valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recode Ansiedad: Ansiedad autopercibida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_categoricas=[\"P10000901\", \"P10000902\", \"P10000903\", \"P10000904\", \"P10000905\", \"P10000906\", \"P10000907\"]\n",
    "for col in cols_categoricas:\n",
    "    print(f\"{col}: {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeo de categorías a valores numéricos\n",
    "mapa_categorias = {\n",
    "    \"Ningun día\": 0,\n",
    "    \"Varios días\": 1,\n",
    "    \"Más de la mitad de los días\": 2,\n",
    "    \"Casi todos los días\": 3,\n",
    "}\n",
    "\n",
    "# Convertir categorías a valores numéricos\n",
    "for col in cols_categoricas:\n",
    "    df[col] = df[col].map(mapa_categorias).astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para ver tab de frecuencia de los codigos PXXXXXXXXXX\n",
    "# Contar valores, incluyendo NaN\n",
    "frecuencia = df[\"P10000902\"].value_counts(dropna=False).sort_index()\n",
    "\n",
    "# Calcular porcentaje\n",
    "porcentaje = (frecuencia / frecuencia.sum()) * 100\n",
    "\n",
    "# Calcular frecuencia acumulada\n",
    "frecuencia_acumulada = frecuencia.cumsum()\n",
    "\n",
    "# Calcular porcentaje acumulado\n",
    "porcentaje_acumulado = porcentaje.cumsum()\n",
    "\n",
    "# Crear DataFrame con los resultados\n",
    "tabla_frecuencia = pd.DataFrame({\n",
    "    \"Frecuencia\": frecuencia,\n",
    "    \"Porcentaje\": porcentaje,\n",
    "    \"Frecuencia Acumulada\": frecuencia_acumulada,\n",
    "    \"Porcentaje Acumulado\": porcentaje_acumulado\n",
    "})\n",
    "\n",
    "# Agregar fila de total\n",
    "tabla_frecuencia.loc[\"Total\"] = [\n",
    "    frecuencia.sum(), 100, None, None\n",
    "]\n",
    "\n",
    "# Mostrar tabla\n",
    "print(tabla_frecuencia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar que las columnas sean numéricas antes de sumar\n",
    "cols_ansiedad = [\"P10000901\", \"P10000902\", \"P10000903\", \"P10000904\", \"P10000905\", \"P10000906\", \"P10000907\"]\n",
    "df[cols_ansiedad] = df[cols_ansiedad].apply(pd.to_numeric, errors=\"coerce\")  # Convierte a numérico, forzando NaN en errores\n",
    "\n",
    "# Sumar las columnas de ansiedad\n",
    "df[\"ansioso\"] = df[cols_ansiedad].sum(axis=1, skipna=False)  # Respeta los NaN en la suma\n",
    "\n",
    "# Crear la variable categórica cat_ansioso sin modificar NaN\n",
    "df[\"cat_ansioso\"] = pd.NA\n",
    "df.loc[df[\"ansioso\"].notna() & (df[\"ansioso\"] < 5), \"cat_ansioso\"] = 0\n",
    "df.loc[df[\"ansioso\"].notna() & (df[\"ansioso\"] >= 5), \"cat_ansioso\"] = 1\n",
    "\n",
    "# Etiquetas para la variable categórica\n",
    "ansiedad_labels = {0: \"Menor nivel ansiedad\", 1: \"Mayor nivel ansiedad\"}\n",
    "df[\"cat_ansioso_label\"] = df[\"cat_ansioso\"].map(ansiedad_labels)\n",
    "\n",
    "# Mostrar la tabla de frecuencia\n",
    "tabla_frecuencia_ansioso = df[\"cat_ansioso_label\"].value_counts(dropna=False).to_frame(name=\"Frecuencia\")\n",
    "tabla_frecuencia_ansioso[\"Porcentaje\"] = (tabla_frecuencia_ansioso[\"Frecuencia\"] / tabla_frecuencia_ansioso[\"Frecuencia\"].sum()) * 100\n",
    "tabla_frecuencia_ansioso[\"Frecuencia Acumulada\"] = tabla_frecuencia_ansioso[\"Frecuencia\"].cumsum()\n",
    "tabla_frecuencia_ansioso[\"Porcentaje Acumulado\"] = tabla_frecuencia_ansioso[\"Porcentaje\"].cumsum()\n",
    "\n",
    "# Agregar fila de totales\n",
    "total_frecuencia = tabla_frecuencia_ansioso[\"Frecuencia\"].sum()\n",
    "total_porcentaje = tabla_frecuencia_ansioso[\"Porcentaje\"].sum()\n",
    "tabla_frecuencia_ansioso.loc[\"Total\"] = [total_frecuencia, total_porcentaje, None, None]\n",
    "\n",
    "print(tabla_frecuencia_ansioso)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recode Depresion: Depresion autopercibida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_categoricas=[\"P10001001\", \"P10001002\", \"P10001003\", \"P10001004\", \"P10001005\", \"P10001006\", \"P10001007\", \"P10001008\", \"P10001009\"]\n",
    "for col in cols_categoricas:\n",
    "    print(f\"{col}: {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeo de categorías a valores numéricos\n",
    "mapa_categorias = {\n",
    "    \"Ningun día\": 0,\n",
    "    \"Varios días\": 1,\n",
    "    \"Más de la mitad de los días\": 2,\n",
    "    \"Casi todos los días\": 3,\n",
    "}\n",
    "\n",
    "# Convertir categorías a valores numéricos\n",
    "for col in cols_categoricas:\n",
    "    df[col] = df[col].map(mapa_categorias).astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para ver tab de frecuencia de los codigos PXXXXXXXXXX\n",
    "# Contar valores, incluyendo NaN\n",
    "frecuencia = df[\"P10001001\"].value_counts(dropna=False).sort_index()\n",
    "\n",
    "# Calcular porcentaje\n",
    "porcentaje = (frecuencia / frecuencia.sum()) * 100\n",
    "\n",
    "# Calcular frecuencia acumulada\n",
    "frecuencia_acumulada = frecuencia.cumsum()\n",
    "\n",
    "# Calcular porcentaje acumulado\n",
    "porcentaje_acumulado = porcentaje.cumsum()\n",
    "\n",
    "# Crear DataFrame con los resultados\n",
    "tabla_frecuencia = pd.DataFrame({\n",
    "    \"Frecuencia\": frecuencia,\n",
    "    \"Porcentaje\": porcentaje,\n",
    "    \"Frecuencia Acumulada\": frecuencia_acumulada,\n",
    "    \"Porcentaje Acumulado\": porcentaje_acumulado\n",
    "})\n",
    "\n",
    "# Agregar fila de total\n",
    "tabla_frecuencia.loc[\"Total\"] = [\n",
    "    frecuencia.sum(), 100, None, None\n",
    "]\n",
    "\n",
    "# Mostrar tabla\n",
    "print(tabla_frecuencia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las columnas para la variable \"deprimido\"\n",
    "cols_depresion = [\"P10001001\", \"P10001002\", \"P10001003\", \"P10001004\", \n",
    "                  \"P10001005\", \"P10001006\", \"P10001007\", \"P10001008\", \"P10001009\"]\n",
    "\n",
    "# Asegurar que las columnas sean numéricas antes de sumar\n",
    "df[cols_depresion] = df[cols_depresion].apply(pd.to_numeric, errors=\"coerce\")  # Convierte a numérico, forzando NaN en errores\n",
    "\n",
    "# Sumar las columnas de depresión\n",
    "df[\"deprimido\"] = df[cols_depresion].sum(axis=1, skipna=False)  # Respeta los NaN en la suma\n",
    "\n",
    "# Crear la variable categórica cat_depresion sin modificar NaN\n",
    "df[\"cat_depresion\"] = pd.NA\n",
    "df.loc[df[\"deprimido\"].notna() & (df[\"deprimido\"] < 7), \"cat_depresion\"] = 0\n",
    "df.loc[df[\"deprimido\"].notna() & (df[\"deprimido\"] >= 7), \"cat_depresion\"] = 1\n",
    "\n",
    "# Etiquetas para la variable categórica\n",
    "depresion_labels = {0: \"Menor nivel depresion\", 1: \"Mayor nivel depresion\"}\n",
    "df[\"cat_depresion_label\"] = df[\"cat_depresion\"].map(depresion_labels)\n",
    "\n",
    "# Crear la tabla de frecuencia\n",
    "tabla_frecuencia_depresion = df[\"cat_depresion_label\"].value_counts(dropna=False).to_frame(name=\"Frecuencia\")\n",
    "tabla_frecuencia_depresion[\"Porcentaje\"] = (tabla_frecuencia_depresion[\"Frecuencia\"] / tabla_frecuencia_depresion[\"Frecuencia\"].sum()) * 100\n",
    "tabla_frecuencia_depresion[\"Frecuencia Acumulada\"] = tabla_frecuencia_depresion[\"Frecuencia\"].cumsum()\n",
    "tabla_frecuencia_depresion[\"Porcentaje Acumulado\"] = tabla_frecuencia_depresion[\"Porcentaje\"].cumsum()\n",
    "\n",
    "# Agregar fila de totales\n",
    "total_frecuencia = tabla_frecuencia_depresion[\"Frecuencia\"].sum()\n",
    "total_porcentaje = tabla_frecuencia_depresion[\"Porcentaje\"].sum()\n",
    "tabla_frecuencia_depresion.loc[\"Total\"] = [total_frecuencia, total_porcentaje, None, None]\n",
    "\n",
    "# Mostrar la tabla de frecuencia\n",
    "print(tabla_frecuencia_depresion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SALUD FISICA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTA: \n",
    "Revisar estos codigos usando el Marco Instrumental de CaliBRANDO\n",
    "\n",
    "saludfisica = $P10000302$\n",
    "\n",
    "saludmental = $P10000402$\n",
    "\n",
    "altura = $P10000601$\n",
    "\n",
    "peso = $P10000602$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummies de salud física\n",
    "df['dsaludfisica7'] = (df['P10000302'] >= 7).astype(int)\n",
    "df['dsaludfisica14'] = (df['P10000302'] >= 14).astype(int)\n",
    "\n",
    "# Dummies de salud mental\n",
    "df['dsaludmental7'] = (df['P10000402'] >= 7).astype(int)\n",
    "df['dsaludmental14'] = (df['P10000402'] >= 14).astype(int)\n",
    "\n",
    "# IMC\n",
    "df['altura2'] = df['P10000601'] ** 2\n",
    "df['imc2'] = df['P10000602'] / df['altura2']\n",
    "\n",
    "# Clasificación del IMC sin modificar NaN\n",
    "df['imc'] = pd.cut(df['imc2'], bins=[-float('inf'), 18.5, 25, 30, 59], labels=[1, 2, 3, 4])\n",
    "\n",
    "# Convertir a int solo los valores no nulos\n",
    "df['imc'] = df['imc'].astype('Int64')  # Usa 'Int64' para manejar NaN sin errores\n",
    "\n",
    "# Etiquetas del IMC\n",
    "imc_labels = {1: \"Bajo peso\", 2: \"Normal\", 3: \"Sobrepeso\", 4: \"Obesidad\"}\n",
    "df['imc_label'] = df['imc'].map(imc_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular frecuencia absoluta\n",
    "frecuencia = df[\"dsaludfisica7\"].value_counts(dropna=False).sort_index()\n",
    "# Calcular total sin incluir NaN\n",
    "total_sin_na = df[\"dsaludfisica7\"].count()\n",
    "# Calcular porcentajes correctamente\n",
    "porcentaje = (frecuencia / total_sin_na) * 100\n",
    "# Crear DataFrame\n",
    "tabla_frecuencia = pd.DataFrame({\n",
    "    \"Freq.\": frecuencia,\n",
    "    \"Percent\": porcentaje\n",
    "})\n",
    "# Agregar columna acumulada\n",
    "tabla_frecuencia[\"Cum.\"] = tabla_frecuencia[\"Percent\"].cumsum()\n",
    "# Agregar fila de totales\n",
    "tabla_frecuencia.loc[\"Total\"] = [frecuencia.sum(), 100, None]\n",
    "# Redondear como en Stata\n",
    "tabla_frecuencia = tabla_frecuencia.round(2)\n",
    "print(tabla_frecuencia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular frecuencia absoluta\n",
    "frecuencia = df[\"dsaludfisica14\"].value_counts(dropna=False).sort_index()\n",
    "# Calcular total sin incluir NaN\n",
    "total_sin_na = df[\"dsaludfisica14\"].count()\n",
    "# Calcular porcentajes correctamente\n",
    "porcentaje = (frecuencia / total_sin_na) * 100\n",
    "# Crear DataFrame\n",
    "tabla_frecuencia = pd.DataFrame({\n",
    "    \"Freq.\": frecuencia,\n",
    "    \"Percent\": porcentaje\n",
    "})\n",
    "# Agregar columna acumulada\n",
    "tabla_frecuencia[\"Cum.\"] = tabla_frecuencia[\"Percent\"].cumsum()\n",
    "# Agregar fila de totales\n",
    "tabla_frecuencia.loc[\"Total\"] = [frecuencia.sum(), 100, None]\n",
    "# Redondear como en Stata\n",
    "tabla_frecuencia = tabla_frecuencia.round(2)\n",
    "print(tabla_frecuencia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular frecuencia y porcentaje con etiquetas en lugar de números\n",
    "frecuencia = df[\"imc_label\"].value_counts(dropna=False)  \n",
    "porcentaje = df[\"imc_label\"].value_counts(normalize=True, dropna=False) * 100  \n",
    "\n",
    "# Crear DataFrame\n",
    "tabla_frecuencia = pd.DataFrame({\n",
    "    \"Frecuencia\": frecuencia,\n",
    "    \"Porcentaje\": porcentaje\n",
    "})\n",
    "\n",
    "# Agregar columna de frecuencia acumulada\n",
    "tabla_frecuencia[\"Frecuencia Acumulada\"] = tabla_frecuencia[\"Frecuencia\"].cumsum()\n",
    "tabla_frecuencia[\"Porcentaje Acumulado\"] = tabla_frecuencia[\"Porcentaje\"].cumsum()\n",
    "\n",
    "# Agregar fila de totales\n",
    "total_frecuencia = tabla_frecuencia[\"Frecuencia\"].sum()\n",
    "total_porcentaje = tabla_frecuencia[\"Porcentaje\"].sum()\n",
    "tabla_frecuencia.loc[\"Total\"] = [total_frecuencia, total_porcentaje, None, None]\n",
    "\n",
    "print(tabla_frecuencia)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INGRESOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTA: \n",
    "* Los siguientes codigos indican el procesamiento de la variable de ingresos que es categorica, para volverla continua. Se presenta por anio\n",
    "* Este codigo fue creado por Eduardo LORA\n",
    "* Para alicar este codigo por anio, es necesario revisar los salarios minimos de cada anio. Para el 2024, se debe pensar si extender el limite superior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de mapeo para convertir ingresos a valores numéricos\n",
    "ingresos_map = {\n",
    "    \"No tiene ingresos\": np.nan,\n",
    "    \"Mas de 8 SMMLV\": 5,\n",
    "    \"Menos de 1 SMMLV\": 1,\n",
    "    \"Más de 1 SMMLV y menos de 2  SMMLV\": 2,\n",
    "    \"Más de 2 SMMLV y menos de 4 SMMLV\": 3,\n",
    "    \"Más de 4 SMMLV y menos de 8 SMMLV\": 4,\n",
    "    \"No sabe ó no responde\": np.nan  # En Stata este valor se excluye en los cálculos\n",
    "}\n",
    "\n",
    "# Aplicar el mapeo\n",
    "df[\"promedioingresos1\"] = df[\"P07000101\"].map(ingresos_map)\n",
    "\n",
    "# Generar la tabla de frecuencias\n",
    "tabla_frecuencias = df[\"P07000101\"].value_counts(dropna=False).reset_index()\n",
    "tabla_frecuencias.columns = [\"Promedio de ingresos\", \"Freq.\"]\n",
    "\n",
    "# Calcular el porcentaje y acumulado\n",
    "tabla_frecuencias[\"Percent\"] = (tabla_frecuencias[\"Freq.\"] / tabla_frecuencias[\"Freq.\"].sum()) * 100\n",
    "tabla_frecuencias[\"Cum.\"] = tabla_frecuencias[\"Percent\"].cumsum()\n",
    "\n",
    "# Mostrar la tabla\n",
    "print(tabla_frecuencias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingresoMax=10000000\n",
    "\n",
    "# Definir los rangos mínimos y máximos de ingresos por año\n",
    "rangos_ingresos = {\n",
    "    2014: [0, 616027, 1232054, 2464108, 4928216, ingresoMax],\n",
    "    2015: [0, 644350, 1288700, 2577400, 5154800, ingresoMax],\n",
    "    2016: [0, 689454, 1378908, 2757816, 5515632, ingresoMax],\n",
    "    2017: [0, 737717, 1475434, 2950868, 5901736, ingresoMax],\n",
    "    2018: [0, 781242, 1562484, 3124968, 6249936, ingresoMax],\n",
    "    2019: [0, 828211, 1656422, 3312844, 6625688, ingresoMax],\n",
    "    2021: [0, 908526, 1817052, 3634104, 7268208, ingresoMax],\n",
    "    2022: [0, 1160000, 2320000, 4640000, 9280000, ingresoMax]\n",
    "}\n",
    "\n",
    "for year in rangos_ingresos.keys():\n",
    "    # Variable aleatoria uniforme entre 0 y 1\n",
    "    df[f'ingc{year}'] = np.where(df['P01000801'] == year, np.random.uniform(size=len(df)), np.nan)\n",
    "\n",
    "    # Obtener el rango de ingresos\n",
    "    df[f'rango_ing{year}'] = np.where(df['P01000801'] == year, df['promedioingresos1'], np.nan)\n",
    "\n",
    "    # Asignar valores mínimos y máximos según el rango de ingresos\n",
    "    df[f'xmin{year}'] = df[f'rango_ing{year}'].map(\n",
    "        lambda x: rangos_ingresos[year][int(x) - 1] if pd.notnull(x) and 1 <= x <= 6 else np.nan\n",
    "    )\n",
    "\n",
    "    df[f'xmax{year}'] = df[f'rango_ing{year}'].map(\n",
    "        lambda x: rangos_ingresos[year][int(x)] if pd.notnull(x) and 1 <= x <= 5 else 10000000\n",
    "    )\n",
    "\n",
    "    # Calcular el ingreso basado en xmin y xmax\n",
    "    df[f'ingreso{year}'] = df[f'xmin{year}'] + (df[f'xmax{year}'] - df[f'xmin{year}']) * df[f'ingc{year}']\n",
    "    \n",
    "    # Logaritmo del ingreso\n",
    "    df[f'lningreso{year}'] = np.log(df[f'ingreso{year}'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suponiendo que tienes un DataFrame llamado df con las columnas mencionadas\n",
    "df['ingresopanel'] = None  # Crear la columna inicialmente\n",
    "\n",
    "# Asignar valores según el año en la columna 'P01000801'\n",
    "for year in [2014, 2015, 2016, 2017, 2018, 2019, 2021, 2022]:\n",
    "    df.loc[df['P01000801'] == year, 'ingresopanel'] = df[f'ingreso{year}']\n",
    "\n",
    "# Convertir la columna a tipo numérico (por si quedan valores nulos o de otro tipo)\n",
    "df['ingresopanel'] = pd.to_numeric(df['ingresopanel'], errors='coerce')\n",
    "\n",
    "# Obtener la media de 'ingresopanel' agrupado por 'P01000801'\n",
    "result = df.groupby('P01000801')['ingresopanel'].mean().reset_index()\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FORMAL/INFORMAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTA:\n",
    "Los siguientes codigos indican el procesamiento de las variables de interes para calcular indicadores de estres, depresion y ansiedad\n",
    "\n",
    "//Informal employment: Non- contribution to health and pension system\n",
    "\n",
    "* salud y pension: $P06000701$\n",
    "\n",
    "* ninguno: $P06000703$\n",
    "\n",
    "* solo salud: $P06000704$\n",
    "\n",
    "* solo pension: $P06000705$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_categoricas=['P06000701', 'P06000703', 'P06000704', 'P06000705']\n",
    "print(df[cols_categoricas].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols_categoricas:\n",
    "    print(f\"{col}: {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeo de categorías a valores numéricos\n",
    "mapa_categorias = {\n",
    "    \"No\": 0,\n",
    "    \"Si\": 1\n",
    "}\n",
    "\n",
    "# Convertir categorías a valores numéricos\n",
    "for col in cols_categoricas:\n",
    "    df[col] = df[col].map(mapa_categorias).astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a numérico si es necesario\n",
    "for col in ['P06000701', 'P06000703', 'P06000704', 'P06000705']:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Inicializar formalidad con NaN\n",
    "df['formalidad'] = None  \n",
    "\n",
    "# Asignar valores según las condiciones\n",
    "df.loc[df['P06000701'] == 1, 'formalidad'] = 1\n",
    "df.loc[(df['P06000703'] == 1) | (df['P06000704'] == 1) | (df['P06000705'] == 1), 'formalidad'] = 0\n",
    "\n",
    "# Convertir formalidad a numérico\n",
    "df['formalidad'] = pd.to_numeric(df['formalidad'], errors='coerce')\n",
    "\n",
    "# Verificar si hay valores NaN\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar tabla de frecuencia\n",
    "frecuencia = df[\"formalidad\"].value_counts(dropna=False)\n",
    "porcentaje = df[\"formalidad\"].value_counts(normalize=True, dropna=False) * 100\n",
    "\n",
    "tabla_frecuencia = pd.DataFrame({\n",
    "    \"Frecuencia\": frecuencia,\n",
    "    \"Porcentaje\": porcentaje\n",
    "})\n",
    "\n",
    "tabla_frecuencia[\"Frecuencia Acumulada\"] = tabla_frecuencia[\"Frecuencia\"].cumsum()\n",
    "tabla_frecuencia[\"Porcentaje Acumulado\"] = tabla_frecuencia[\"Porcentaje\"].cumsum()\n",
    "\n",
    "# Total\n",
    "total_frecuencia = tabla_frecuencia[\"Frecuencia\"].sum()\n",
    "total_porcentaje = tabla_frecuencia[\"Porcentaje\"].sum()\n",
    "tabla_frecuencia.loc[\"Total\"] = [total_frecuencia, total_porcentaje, None, None]\n",
    "\n",
    "print(tabla_frecuencia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MINORIA ETNICA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* etnia POLIS: $P02001201$ (desde 2014 a 2019)\n",
    "\n",
    "* etnia DANE: $P02001202$ (desde 2021 en adelante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_categoricas=['P02001201', 'P02001202']\n",
    "print(df[cols_categoricas].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols_categoricas:\n",
    "    print(f\"{col}: {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores de el Archivo Stata, mal puestos!!!!\n",
    "mapa_p02001201 = {\n",
    "    'Indígena': 0,\n",
    "    'Gitano': 0,\n",
    "    'Raizal': 1,\n",
    "    'Palenquero': 1,\n",
    "    'Negro ó afro': 0,\n",
    "    'Ninguno': None\n",
    "}\n",
    "\n",
    "mapa_p02001202 = {\n",
    "    'Blanco': 1,\n",
    "    'Mestizo': 1,\n",
    "    'Indigena': 1,\n",
    "    'Negro ó afro': 1,\n",
    "    'Otro': 1,\n",
    "    'Ninguno': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como creo que se correguiria Segun las categorias!!\n",
    "mapa_p02001201 = {\n",
    "    'Indígena': 1,\n",
    "    'Gitano': 1,\n",
    "    'Raizal': 1,\n",
    "    'Palenquero': 1,\n",
    "    'Negro ó afro': 1,\n",
    "    'Ninguno': None\n",
    "}\n",
    "\n",
    "mapa_p02001202 = {\n",
    "    'Blanco': 0,\n",
    "    'Mestizo': 0,\n",
    "    'Indigena': 1,\n",
    "    'Negro ó afro': 1,\n",
    "    'Otro': 0,\n",
    "    'Ninguno': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar la columna 'minoriaetnica' con valores nulos\n",
    "df['minoriaetnica'] = None\n",
    "\n",
    "# Definir el mapeo de valores para P02001201 (2014-2019) y P02001202 (2021 en adelante)\n",
    "mapa_p02001201 = {\n",
    "    'Indígena': 1,\n",
    "    'Gitano': 1,\n",
    "    'Raizal': 1,\n",
    "    'Palenquero': 1,\n",
    "    'Negro ó afro': 1,\n",
    "    'Ninguno': None\n",
    "}\n",
    "\n",
    "mapa_p02001202 = {\n",
    "    'Blanco': 0,\n",
    "    'Mestizo': 0,\n",
    "    'Indigena': 1,\n",
    "    'Negro ó afro': 1,\n",
    "    'Otro': 0,\n",
    "    'Ninguno': None\n",
    "}\n",
    "\n",
    "# Aplicar el mapeo a las columnas correspondientes\n",
    "df['minoriaetnica'] = df['P02001201'].map(mapa_p02001201)\n",
    "\n",
    "# Si existe P02001202, actualizar los valores en base a esta columna\n",
    "df.loc[df['P02001202'].notna(), 'minoriaetnica'] = df['P02001202'].map(mapa_p02001202)\n",
    "\n",
    "# Convertir la columna a tipo numérico\n",
    "df['minoriaetnica'] = pd.to_numeric(df['minoriaetnica'], errors='coerce')\n",
    "\n",
    "# Mostrar tabla de frecuencia\n",
    "frecuencia = df[\"minoriaetnica\"].value_counts(dropna=False)  \n",
    "porcentaje = df[\"minoriaetnica\"].value_counts(normalize=True, dropna=False) * 100  \n",
    "\n",
    "# Crear DataFrame de resumen\n",
    "tabla_frecuencia = pd.DataFrame({\n",
    "    \"Frecuencia\": frecuencia,\n",
    "    \"Porcentaje\": porcentaje\n",
    "})\n",
    "\n",
    "# Agregar columna de frecuencia acumulada\n",
    "tabla_frecuencia[\"Frecuencia Acumulada\"] = tabla_frecuencia[\"Frecuencia\"].cumsum()\n",
    "tabla_frecuencia[\"Porcentaje Acumulado\"] = tabla_frecuencia[\"Porcentaje\"].cumsum()\n",
    "\n",
    "# Agregar fila de totales\n",
    "total_frecuencia = tabla_frecuencia[\"Frecuencia\"].sum()\n",
    "total_porcentaje = tabla_frecuencia[\"Porcentaje\"].sum()\n",
    "tabla_frecuencia.loc[\"Total\"] = [total_frecuencia, total_porcentaje, None, None]\n",
    "\n",
    "# Renombrar valores para que coincidan con Stata\n",
    "tabla_frecuencia.rename(index={0.0: \"No minoria\", 1.0: \"Minoria\"}, inplace=True)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(tabla_frecuencia)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la nueva columna NSE a partir de P02000801\n",
    "df['NSE'] = df['P02000801']\n",
    "\n",
    "# Asignar valores según las condiciones\n",
    "df.loc[df['P02000801'].isin([1, 2]), 'NSE'] = 1  # NSE Bajo (estrato 1 y 2)\n",
    "df.loc[df['P02000801'].isin([3, 4]), 'NSE'] = 2  # NSE Medio (estrato 3 y 4)\n",
    "df.loc[df['P02000801'].isin([5, 6]), 'NSE'] = 3  # NSE Alto (estrato 5 y 6)\n",
    "\n",
    "# Convertir a tipo numérico\n",
    "df['NSE'] = pd.to_numeric(df['NSE'], errors='coerce')\n",
    "\n",
    "# Etiquetas para los niveles socioeconómicos\n",
    "nse_labels = {1: \"NSE Bajo\", 2: \"NSE Medio\", 3: \"NSE Alto\"}\n",
    "\n",
    "# Calcular frecuencias y porcentajes\n",
    "frecuencia = df[\"NSE\"].value_counts(dropna=False).sort_index()\n",
    "porcentaje = df[\"NSE\"].value_counts(normalize=True, dropna=False).sort_index() * 100\n",
    "\n",
    "# Crear DataFrame de resumen\n",
    "tabla_frecuencia = pd.DataFrame({\n",
    "    \"Frecuencia\": frecuencia,\n",
    "    \"Porcentaje\": porcentaje\n",
    "})\n",
    "\n",
    "# Agregar columna de frecuencia acumulada\n",
    "tabla_frecuencia[\"Frecuencia Acumulada\"] = tabla_frecuencia[\"Frecuencia\"].cumsum()\n",
    "tabla_frecuencia[\"Porcentaje Acumulado\"] = tabla_frecuencia[\"Porcentaje\"].cumsum()\n",
    "\n",
    "# Agregar fila de totales\n",
    "total_frecuencia = tabla_frecuencia[\"Frecuencia\"].sum()\n",
    "total_porcentaje = tabla_frecuencia[\"Porcentaje\"].sum()\n",
    "tabla_frecuencia.loc[\"Total\"] = [total_frecuencia, total_porcentaje, None, None]\n",
    "\n",
    "# Renombrar los índices con etiquetas\n",
    "tabla_frecuencia.rename(index=nse_labels, inplace=True)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(tabla_frecuencia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"insumos/data/data_&_variables_nuevas_Calipedia.csv\", index=False, encoding=\"utf-8\", sep=\";\")\n",
    "#df.to_excel(\"insumos/datos_con_scripts_Calipedia.xlsx\", index=False, engine=\"openpyxl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
